#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import sys

import argparse

import pickle

import  numpy as np

# from scipy.stats import randint as sp_randint
from scipy.stats import uniform

from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import train_test_split
from sklearn.model_selection import RandomizedSearchCV

from sklearn.preprocessing import StandardScaler

from sklearn.metrics import confusion_matrix, accuracy_score

from prioretizer.grasslib.configurator import Params
from prioretizer.grasslib.grasslib import GRASS

from prioretizer.defaults import DEFAULT_CONFIG_NAME


def parse_args():
    parser = argparse.ArgumentParser(description='Create Database for logging ranging.')

    parser.add_argument(
        '--config',
        dest='config',
        action='store',
        default=DEFAULT_CONFIG_NAME,
        help='Config file (default: %s)' % (DEFAULT_CONFIG_NAME, )
    )
    parser.add_argument(
        '--x',
        dest='x',
        action='store',
        required=True,
        help='List of factor rasters (comma-separated: raster1,raster2,...)'
    )
    parser.add_argument(
        '--y',
        dest='y',
        action='store',
        required=True,
        help='Name of result raster.'
    )
    parser.add_argument(
        '--result',
        dest='result',
        action='store',
        required=True,
        help='Name of result file to store model.'
    )
    parser.add_argument(
        '--result_raster',
        dest='result_raster',
        action='store',
        required=True,
        help='Name of result raster.'
    )
    parser.add_argument(
        '--human',
        dest='human',
        action='store',
        help='Name of human-readable resume file.'
    )
    parser.add_argument(
        '--overwrite',
        dest='overwrite',
        action='store_const',
        const=True,
        default=False,
        help='Overwrite existing result file (True or False).'
    )
    args = parser.parse_args()

    return args

class Trainer:
    def __init__(self, X, y):
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)
        self.X_train = X_train
        self.X_test = X_test
        self.y_train = y_train
        self.y_test = y_test

        stdsc = StandardScaler()
        self.X_train_std = stdsc.fit_transform(X_train)
        self.X_test_std = stdsc.transform(X_test)

        self.scaler = stdsc
        self.model = None
        self.train_description = None

    def train(self):
        logistic = LogisticRegression(class_weight="balanced", penalty='l1')
        grid_search_params = {'C': uniform(0.001, 1.5)}
        gs = RandomizedSearchCV(
            logistic,
            grid_search_params,
            cv=10, scoring='accuracy',
            n_jobs=-1,
            random_state=1
        )

        gs.fit(self.X_train_std, self.y_train)

        self.model = gs.best_estimator_
        self.train_description = gs.cv_results_

    def predict_probas(self, X):
        if self.model is None:
            raise RuntimeError('Train model first, then use it')

        probas = self.model.predict_proba(X)
        # probas is numpy array somethink like:
        #           p(y==0) ,    p(y==1)
        # array([[0.50226361, 0.49773639],
        # [0.94820054, 0.05179946],
        # [0.34371554, 0.65628446]])

        return probas[:, 1]

    def describe(self):

        test_predict = self.model.predict(self.X_test_std)
        test_accuracy = accuracy_score(self.y_test, test_predict)

        train_predict = self.model.predict(self.X_train_std)
        train_accuracy = accuracy_score(self.y_train, train_predict)

        cm = confusion_matrix(self.y_test, test_predict)

        params = dict(
            coefs = self.model.coef_,
            intercept = self.model.intercept_,
            train_acc = train_accuracy,
            test_acc = test_accuracy,
            cm = cm
        )

        description = """
        MODEL: Weighted Logistic Regresion,
        coefs: %(coefs)s,
        intercept: %(intercept)s
        ------------------------------------
        Train accuracy: %(train_acc)s
        Test accuracy: %(test_acc)s
        
        Test confusion matrix = %(cm)s
        """ % params

        return description

def main():
    args = parse_args()
    args = vars(args)

    overwrite = args['overwrite']
    x = args['x'].split(',')
    y = args['y']

    result = args['result']
    result_raster = args['result_raster']
    human = args['human']

    config = args['config']
    config_params = Params(config)

    grass_lib = config_params.grass_lib
    grass_exec = config_params.grass_exec

    location = config_params.location
    dbase = config_params.grassdata

    grs = GRASS(
        gisexec=grass_exec,
        gisbase=grass_lib,
        grassdata=dbase,
        location=location,
        init_loc=True
    )
    X = grs.rasters_to_array(x)
    Y = grs.raster_to_array(y)

    if os.path.isfile(result) and not overwrite:
        sys.exit("File %s exists. Use --overwrite flag or other filename." % (result, ))

    if (human is not None) and os.path.isfile(human) and not overwrite:
        sys.exit("File %s exists. Use --overwrite flag or other filename." % (human, ))

    trainer = Trainer(X, Y)
    trainer.train()
    pickle.dump((trainer.model, trainer.scaler), open(result, 'wb'), protocol=2)

    probas = trainer.predict_probas(X)
    grs.array_to_rast(probas, result_raster, overwrite=overwrite)

    if human is not None:
        human_file = open(human, 'w')
        human_file.write(trainer.describe())


if __name__ == '__main__':
    main()

